                 0                1                  2      3     4              5               6                  7                8                 9                10
0            qvalue           svalue             pvalue     TP    FP             TN              FN                FDR              FNR              sens           cutoff
1               0.0  0.0022304833401  7.28306304154e-14    1.0   0.0  27.4041450777   358.595854922  2.48837994481e-12   0.929041206837  0.00278089968589    7.22470378876
2  0.00999999977648              1.0     0.117941431701  360.0   3.0  24.4041450777  -0.40414507772   0.00890533812344              0.0               1.0    1.67986810207
3    0.019999999553              1.0     0.242241606116  360.0   7.0  20.4041450777  -0.40414507772     0.018090903759              0.0               1.0     1.0448975563
4   0.0500000007451              1.0     0.686355412006  359.0  19.0  8.40414507772   0.59585492228    0.0497359000146  0.0258009582758    0.998342987234  -0.363087415695
5     0.10000000149              1.0     0.962249279022  361.0  26.0  1.40414507772  -1.40414507772    0.0681385472417              0.0               1.0   -1.58573198318
6     0.20000000298              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
7    0.300000011921              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
8     0.40000000596              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
9               0.5              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
                0       1               2      3     4              5               6                7                 8               9                10
0           qvalue  svalue          pvalue     TP    FP             TN              FN              FDR               FNR            sens           cutoff
1  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -2.02625370026
2  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.83242416382
3  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.63859462738
4  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.44476509094
5  0.0679288357496     1.0  0.957299530506  360.0  26.0  1.40414507772  -0.40414507772  0.0679288357496               0.0             1.0    -1.2509354353
6  0.0610772445798     1.0  0.854045271873  360.0  23.0  4.40414507772  -0.40414507772  0.0611096955836  0.00264257704839             1.0   -1.05710589886
7  0.0580131188035     1.0  0.809070765972  360.0  22.0  5.40414507772  -0.40414507772  0.0580131188035               0.0             1.0   -0.86327624321
8  0.0550636425614     1.0  0.763907313347  359.0  21.0  6.40414507772   0.59585492228  0.0550636425614   0.0510000698268  0.998342987234  -0.669446706772
9  0.0541973598301     1.0  0.750078678131  358.0  21.0  6.40414507772   1.59585492228  0.0542384944856    0.146102204919  0.995562087548  -0.475617080927
...
                   0                1                  2      3    4              5              6                  7               8                 9              10
42  1.30287125533e-09   0.311152428389  5.31952792926e-09  112.0  0.0  27.4041450777  247.595854922  1.30287125533e-09  0.900388717651    0.311460764819  5.92075920105
43  7.30672522486e-10   0.238661706448   2.2979342873e-09   86.0  0.0  27.4041450777  273.595854922  7.33764049521e-10  0.909010231495    0.239157372986  6.11458873749
44  2.59888111032e-10   0.150557622313  5.13437514726e-10   54.0  0.0  27.4041450777  305.595854922  2.59888111032e-10  0.917670667171    0.150168583038  6.30841827393
45  1.07541170413e-10   0.100371748209  1.41639588946e-10   36.0  0.0  27.4041450777  323.595854922  1.07541170413e-10  0.921904742718    0.100112388692   6.5022482872
46  4.70016491005e-11  0.0501858741045  3.13288284204e-11   18.0  0.0  27.4041450777  341.595854922  4.75734070193e-11  0.925724625587    0.050056194346  6.69607782364
47  3.14423487247e-11  0.0356877334416  1.47242218418e-11   13.0  0.0  27.4041450777  346.595854922  3.14423487247e-11  0.926759541035   0.0361516959165  6.88990736008
48  8.68656969272e-12  0.0133828995749  1.56163970644e-12    5.0  0.0  27.4041450777  354.595854922  8.89267045417e-12  0.928296625614   0.0139044984294  7.08373689651
49  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.27756643295
50  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.47139596939
51  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.66522550583
         0         1         2         3         4         5         6         7         8         9     ...           41        42        43        44        45        46  \
0 -2.026254 -1.832424 -1.638595 -1.444765 -1.250935 -1.057106 -0.863276 -0.669447 -0.475617 -0.281788    ...     5.920759  6.114589  6.308418  6.502248  6.696078  6.889907

         47        48        49        50
0  7.083737  7.277566  7.471396  7.665226

[1 rows x 51 columns]
    0    1    2    3    4    5    6    7    8    9    ...           41        42        43        44        45        46        47       48       49       50
0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   ...     0.311152  0.238662  0.150558  0.100372  0.050186  0.035688  0.013383  0.00223  0.00223  0.00223

[1 rows x 51 columns]
         0         1         2         3         4         5         6         7         8         9       ...                 41            42            43            44  \
0  0.068139  0.068139  0.068139  0.068139  0.067929  0.061077  0.058013  0.055064  0.054197  0.046554      ...       1.302871e-09  7.306725e-10  2.598881e-10  1.075412e-10

             45            46            47            48            49            50
0  4.700165e-11  3.144235e-11  8.686570e-12  2.488380e-12  2.488380e-12  2.488380e-12

[1 rows x 51 columns]
       0         1         2         3         4        5         6         7         8         9      ...          377       378       379       380       381       382  \
0  5.50869  4.766003  4.248959  5.561705  5.273554  5.58179  6.118019  3.043664  6.459825  4.759176    ...     6.160937  4.082398  5.483152  5.730392  5.586233 -1.059943

        383       384       385       386
0  5.416876  5.901189  6.668849  5.789939

[1 rows x 387 columns]
        0         1         2         3         4         5         6        7         8         9      ...          377      378       379       380       381       382  \
0  0.817348  2.051535 -0.005753  0.297511  0.007239 -1.437819 -0.367768  1.16451  1.192095  0.197512    ...    -2.231404  0.22299 -0.087768 -0.406222  0.089297 -0.082859

        383       384       385       386
0 -1.469323 -0.200505  0.204298  1.270099

[1 rows x 387 columns]
                     0       1      2                3                  4                5                  6                  7                  8
0  transition_group_id  run_id  decoy          d_score            m_score  peak_group_rank           pg_score            h_score           h0_score
1             459_run0       0      0    5.50868988037  1.09357003453e-08                1      0.99999499537     0.999997328445  2.66976244721e-06
2             459_run0       0      0   -1.30364465714    0.0679288357496                3  0.000175293855794  8.77436767265e-10  2.66976244721e-06
3             459_run0       0      0   -4.72917842865    0.0681385472417                7  3.88851250114e-08  1.94606129585e-13  2.66976244721e-06
4             459_run0       0      0   -2.79115200043    0.0681385472417                4  3.82922388992e-06  1.91639673239e-11  2.66976244721e-06
5             459_run0       0      0    -1.3000651598    0.0679288357496                2   0.00017696986087  8.85827527822e-10  2.66976244721e-06
6             459_run0       0      0   -3.12633061409    0.0681385472417                5  1.67718461507e-06  8.39372230876e-12  2.66976244721e-06
7             459_run0       0      0   -3.98068499565    0.0681385472417                6  2.17162158049e-07  1.08681904949e-12  2.66976244721e-06
8             460_run0       0      0    4.76600265503  3.51661810782e-07                1     0.999936551642     0.999961096909  3.86832196238e-05
9             460_run0       0      0  -0.359799444675    0.0497359000146                2   0.00226731352787  1.44187769763e-07  3.86832196238e-05
...
                   0  1  2                3                4   5                  6                  7               8
9156  DECOY_592_run0  0  1    -3.0585565567  0.0681385472417  10  1.97975133585e-06  1.35160933632e-06  0.832455912569
9157  DECOY_592_run0  0  1  -0.542050778866  0.0541973598301   2   0.00137243237197  0.000938268380851  0.832455912569
9158  DECOY_592_run0  0  1   -4.28670549393  0.0681385472417  16  1.06635006309e-07  7.28013652377e-08  0.832455912569
9159  DECOY_592_run0  0  1   -3.64450979233  0.0681385472417  13  4.80449179963e-07  3.28010195992e-07  0.832455912569
9160  DECOY_592_run0  0  1   -2.68344449997  0.0681385472417   7  5.00664173409e-06  3.41812836387e-06  0.832455912569
9161  DECOY_592_run0  0  1   -2.83036255836  0.0681385472417   9  3.47432890776e-06  2.37198597753e-06  0.832455912569
9162  DECOY_592_run0  0  1   -2.75949048996  0.0681385472417   8  4.14263355873e-06  2.82825130814e-06  0.832455912569
9163  DECOY_592_run0  0  1   -4.25948238373  0.0681385472417  15  1.13548817053e-07  7.75215311201e-08  0.832455912569
9164  DECOY_592_run0  0  1   -4.12553596497  0.0681385472417  14  1.54874069216e-07  1.05734923442e-07  0.832455912569
9165  DECOY_592_run0  0  1   -3.57327675819  0.0681385472417  12  5.69465197972e-07  3.88782863225e-07  0.832455912569
                     0       1      2                3                  4                5                  6                  7                  8
0  transition_group_id  run_id  decoy          d_score            m_score  peak_group_rank           pg_score            h_score           h0_score
1             459_run0       0      0    5.50868988037  1.09357003453e-08                1      0.99999499537     0.999997328445  2.66976244721e-06
2             459_run0       0      0   -1.30364465714    0.0679288357496                3  0.000175293855794  8.77436767265e-10  2.66976244721e-06
3             459_run0       0      0   -4.72917842865    0.0681385472417                7  3.88851250114e-08  1.94606129585e-13  2.66976244721e-06
4             459_run0       0      0   -2.79115200043    0.0681385472417                4  3.82922388992e-06  1.91639673239e-11  2.66976244721e-06
5             459_run0       0      0    -1.3000651598    0.0679288357496                2   0.00017696986087  8.85827527822e-10  2.66976244721e-06
6             459_run0       0      0   -3.12633061409    0.0681385472417                5  1.67718461507e-06  8.39372230876e-12  2.66976244721e-06
7             459_run0       0      0   -3.98068499565    0.0681385472417                6  2.17162158049e-07  1.08681904949e-12  2.66976244721e-06
8             460_run0       0      0    4.76600265503  3.51661810782e-07                1     0.999936551642     0.999961096909  3.86832196238e-05
9             460_run0       0      0  -0.359799444675    0.0497359000146                2   0.00226731352787  1.44187769763e-07  3.86832196238e-05
...
                   0  1  2                3                4   5                  6                  7               8
9156  DECOY_592_run0  0  1    -3.0585565567  0.0681385472417  10  1.97975133585e-06  1.35160933632e-06  0.832455912569
9157  DECOY_592_run0  0  1  -0.542050778866  0.0541973598301   2   0.00137243237197  0.000938268380851  0.832455912569
9158  DECOY_592_run0  0  1   -4.28670549393  0.0681385472417  16  1.06635006309e-07  7.28013652377e-08  0.832455912569
9159  DECOY_592_run0  0  1   -3.64450979233  0.0681385472417  13  4.80449179963e-07  3.28010195992e-07  0.832455912569
9160  DECOY_592_run0  0  1   -2.68344449997  0.0681385472417   7  5.00664173409e-06  3.41812836387e-06  0.832455912569
9161  DECOY_592_run0  0  1   -2.83036255836  0.0681385472417   9  3.47432890776e-06  2.37198597753e-06  0.832455912569
9162  DECOY_592_run0  0  1   -2.75949048996  0.0681385472417   8  4.14263355873e-06  2.82825130814e-06  0.832455912569
9163  DECOY_592_run0  0  1   -4.25948238373  0.0681385472417  15  1.13548817053e-07  7.75215311201e-08  0.832455912569
9164  DECOY_592_run0  0  1   -4.12553596497  0.0681385472417  14  1.54874069216e-07  1.05734923442e-07  0.832455912569
9165  DECOY_592_run0  0  1   -3.57327675819  0.0681385472417  12  5.69465197972e-07  3.88782863225e-07  0.832455912569
hex digtest pickled classifier: dbf168136800ec7dcd14ab0be7f9a0fefa94876f
pyprophet test_data.txt --random_seed=42 --compute.probabilities --target.compress_results
 config settings:
     apply_scorer: None
     apply_weights: None
     compute.probabilities: True
     d_score.cutoff: -1000.0
     delim.in:
     delim.out:
     export.mayu: False
     final_statistics.emp_p: False
     final_statistics.lambda: 0.4
     final_statistics.pfdr: False
     ignore.invalid_score_columns: 0
     is_test: 0
     multiple_files.merge_results: 0
     num_processes: 1
     out_of_core: 0
     out_of_core.sampling_rate: 0.1
     random_seed: 42
     semi_supervised_learner.initial_fdr: 0.15
     semi_supervised_learner.initial_lambda: 0.4
     semi_supervised_learner.iteration_fdr: 0.02
     semi_supervised_learner.iteration_lambda: 0.4
     semi_supervised_learner.num_iter: 5
     semi_supervised_learner.stat_best: 0
     semi_supervised_learner.use_best: 0
     target.compress_results: 1
     target.dir: None
     target.overwrite: 0
     target.prefix: None
     xeval.fraction: 0.5
     xeval.num_iter: 5
 process test_data.txt
 learn and apply classifier from input data
 data set contains 387 decoy and 387 target transition groups
 summary input file:
    9165 lines
    774 transition groups
    17 scores including main score
 learn and apply scorer
 start 5 cross evals using 1 processes
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 finished cross evals

 data set contains 387 decoy and 387 target transition groups
 mean m_score = 6.130438e-02, std_dev m_score = 1.658378e-02
 mean s_value = 9.800913e-01, std_dev s_value = 1.125709e-01
 Posterior Probability estimation:
 Estimated number of null 68.33 out of a total of 965.
 Prior for a peakgroup: 0.102448961516
 Prior for a chromatogram: 0.929188255613
 Estimated number of true chromatograms: 359.595854922 out of 387
 Number of target data: 3510

 calculated scoring and statistics
 processing input data finished

used parameters:

    apply_scorer                               : None
    apply_weights                              : None
    compute.probabilities                      : True
    d_score.cutoff                             : -1000.0
    delim.in                                   : '\t'
    delim.out                                  : '\t'
    export.mayu                                : False
    final_statistics.emp_p                     : False
    final_statistics.lambda                    : 0.4
    final_statistics.pfdr                      : False
    ignore.invalid_score_columns               : 0
    is_test                                    : 0
    multiple_files.merge_results               : 0
    num_processes                              : 1
    out_of_core                                : 0
    out_of_core.sampling_rate                  : 0.1
    random_seed                                : 42
    semi_supervised_learner.initial_fdr        : 0.15
    semi_supervised_learner.initial_lambda     : 0.4
    semi_supervised_learner.iteration_fdr      : 0.02
    semi_supervised_learner.iteration_lambda   : 0.4
    semi_supervised_learner.num_iter           : 5
    semi_supervised_learner.stat_best          : 0
    semi_supervised_learner.use_best           : 0
    target.compress_results                    : 1
    target.dir                                 : None
    target.overwrite                           : 0
    target.prefix                              : None
    xeval.fraction                             : 0.5
    xeval.num_iter                             : 5


==================================================================================================

   qvalue   svalue        pvalue     TP    FP         TN          FN           FDR       FNR  \
0    0.00  0.00223  7.283063e-14    1.0   0.0  27.404145  358.595855  2.488380e-12  0.929041
1    0.01  1.00000  1.179414e-01  360.0   3.0  24.404145   -0.404145  8.905338e-03  0.000000
2    0.02  1.00000  2.422416e-01  360.0   7.0  20.404145   -0.404145  1.809090e-02  0.000000
3    0.05  1.00000  6.863554e-01  359.0  19.0   8.404145    0.595855  4.973590e-02  0.025801
4    0.10  1.00000  9.622493e-01  361.0  26.0   1.404145   -1.404145  6.813855e-02  0.000000
5    0.20      NaN           NaN    NaN   NaN        NaN         NaN           NaN       NaN
6    0.30      NaN           NaN    NaN   NaN        NaN         NaN           NaN       NaN
7    0.40      NaN           NaN    NaN   NaN        NaN         NaN           NaN       NaN
8    0.50      NaN           NaN    NaN   NaN        NaN         NaN           NaN       NaN

       sens    cutoff
0  0.002781  7.224704
1  1.000000  1.679868
2  1.000000  1.044898
3  0.998343 -0.363087
4  1.000000 -1.585732
5       NaN       NaN
6       NaN       NaN
7       NaN       NaN
8       NaN       NaN

==================================================================================================

WRITTEN:  test_data_summary_stat.csv
WRITTEN:  test_data_full_stat.csv
WRITTEN:  test_data_with_dscore.csv
WRITTEN:  test_data_with_dscore_filtered.csv
WRITTEN:  test_data_report.pdf
WRITTEN:  test_data_cutoffs.txt
WRITTEN:  test_data_svalues.txt
WRITTEN:  test_data_qvalues.txt
WRITTEN:  test_data_dscores_top_target_peaks.txt
WRITTEN:  test_data_dscores_top_decoy_peaks.txt
WRITTEN:  test_data_scorer.bin
WRITTEN:  test_data_weights.txt


                 0                1                  2      3     4              5               6                  7                8                 9                10
0            qvalue           svalue             pvalue     TP    FP             TN              FN                FDR              FNR              sens           cutoff
1               0.0  0.0022304833401  7.28306304154e-14    1.0   0.0  27.4041450777   358.595854922  2.48837994481e-12   0.929041206837  0.00278089968589    7.22470378876
2  0.00999999977648              1.0     0.117941431701  360.0   3.0  24.4041450777  -0.40414507772   0.00890533812344              0.0               1.0    1.67986810207
3    0.019999999553              1.0     0.242241606116  360.0   7.0  20.4041450777  -0.40414507772     0.018090903759              0.0               1.0     1.0448975563
4   0.0500000007451              1.0     0.686355412006  359.0  19.0  8.40414507772   0.59585492228    0.0497359000146  0.0258009582758    0.998342987234  -0.363087415695
5     0.10000000149              1.0     0.962249279022  361.0  26.0  1.40414507772  -1.40414507772    0.0681385472417              0.0               1.0   -1.58573198318
6     0.20000000298              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
7    0.300000011921              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
8     0.40000000596              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
9               0.5              NaN                NaN    NaN   NaN            NaN             NaN                NaN              NaN               NaN              NaN
                0       1               2      3     4              5               6                7                 8               9                10
0           qvalue  svalue          pvalue     TP    FP             TN              FN              FDR               FNR            sens           cutoff
1  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -2.02625370026
2  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.83242416382
3  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.63859462738
4  0.0681385472417     1.0  0.962249279022  361.0  26.0  1.40414507772  -1.40414507772  0.0681385472417               0.0             1.0   -1.44476509094
5  0.0679288357496     1.0  0.957299530506  360.0  26.0  1.40414507772  -0.40414507772  0.0679288357496               0.0             1.0    -1.2509354353
6  0.0610772445798     1.0  0.854045271873  360.0  23.0  4.40414507772  -0.40414507772  0.0611096955836  0.00264257704839             1.0   -1.05710589886
7  0.0580131188035     1.0  0.809070765972  360.0  22.0  5.40414507772  -0.40414507772  0.0580131188035               0.0             1.0   -0.86327624321
8  0.0550636425614     1.0  0.763907313347  359.0  21.0  6.40414507772   0.59585492228  0.0550636425614   0.0510000698268  0.998342987234  -0.669446706772
9  0.0541973598301     1.0  0.750078678131  358.0  21.0  6.40414507772   1.59585492228  0.0542384944856    0.146102204919  0.995562087548  -0.475617080927
...
                   0                1                  2      3    4              5              6                  7               8                 9              10
42  1.30287125533e-09   0.311152428389  5.31952792926e-09  112.0  0.0  27.4041450777  247.595854922  1.30287125533e-09  0.900388717651    0.311460764819  5.92075920105
43  7.30672522486e-10   0.238661706448   2.2979342873e-09   86.0  0.0  27.4041450777  273.595854922  7.33764049521e-10  0.909010231495    0.239157372986  6.11458873749
44  2.59888111032e-10   0.150557622313  5.13437514726e-10   54.0  0.0  27.4041450777  305.595854922  2.59888111032e-10  0.917670667171    0.150168583038  6.30841827393
45  1.07541170413e-10   0.100371748209  1.41639588946e-10   36.0  0.0  27.4041450777  323.595854922  1.07541170413e-10  0.921904742718    0.100112388692   6.5022482872
46  4.70016491005e-11  0.0501858741045  3.13288284204e-11   18.0  0.0  27.4041450777  341.595854922  4.75734070193e-11  0.925724625587    0.050056194346  6.69607782364
47  3.14423487247e-11  0.0356877334416  1.47242218418e-11   13.0  0.0  27.4041450777  346.595854922  3.14423487247e-11  0.926759541035   0.0361516959165  6.88990736008
48  8.68656969272e-12  0.0133828995749  1.56163970644e-12    5.0  0.0  27.4041450777  354.595854922  8.89267045417e-12  0.928296625614   0.0139044984294  7.08373689651
49  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.27756643295
50  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.47139596939
51  2.48837994481e-12  0.0022304833401  7.28306304154e-14    1.0  0.0  27.4041450777  358.595854922  2.48837994481e-12  0.929041206837  0.00278089968589  7.66522550583
         0         1         2         3         4         5         6         7         8         9     ...           41        42        43        44        45        46  \
0 -2.026254 -1.832424 -1.638595 -1.444765 -1.250935 -1.057106 -0.863276 -0.669447 -0.475617 -0.281788    ...     5.920759  6.114589  6.308418  6.502248  6.696078  6.889907

         47        48        49        50
0  7.083737  7.277566  7.471396  7.665226

[1 rows x 51 columns]
    0    1    2    3    4    5    6    7    8    9    ...           41        42        43        44        45        46        47       48       49       50
0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   ...     0.311152  0.238662  0.150558  0.100372  0.050186  0.035688  0.013383  0.00223  0.00223  0.00223

[1 rows x 51 columns]
         0         1         2         3         4         5         6         7         8         9       ...                 41            42            43            44  \
0  0.068139  0.068139  0.068139  0.068139  0.067929  0.061077  0.058013  0.055064  0.054197  0.046554      ...       1.302871e-09  7.306725e-10  2.598881e-10  1.075412e-10

             45            46            47            48            49            50
0  4.700165e-11  3.144235e-11  8.686570e-12  2.488380e-12  2.488380e-12  2.488380e-12

[1 rows x 51 columns]
       0         1         2         3         4        5         6         7         8         9      ...          377       378       379       380       381       382  \
0  5.50869  4.766003  4.248959  5.561705  5.273554  5.58179  6.118019  3.043664  6.459825  4.759176    ...     6.160937  4.082398  5.483152  5.730392  5.586233 -1.059943

        383       384       385       386
0  5.416876  5.901189  6.668849  5.789939

[1 rows x 387 columns]
        0         1         2         3         4         5         6        7         8         9      ...          377      378       379       380       381       382  \
0  0.817348  2.051535 -0.005753  0.297511  0.007239 -1.437819 -0.367768  1.16451  1.192095  0.197512    ...    -2.231404  0.22299 -0.087768 -0.406222  0.089297 -0.082859

        383       384       385       386
0 -1.469323 -0.200505  0.204298  1.270099

[1 rows x 387 columns]
                     0       1      2                3                  4                5                  6                  7                  8
0  transition_group_id  run_id  decoy          d_score            m_score  peak_group_rank           pg_score            h_score           h0_score
1             459_run0       0      0    5.50868988037  1.09357003453e-08                1      0.99999499537     0.999997328445  2.66976244721e-06
2             459_run0       0      0   -1.30364465714    0.0679288357496                3  0.000175293855794  8.77436767265e-10  2.66976244721e-06
3             459_run0       0      0   -4.72917842865    0.0681385472417                7  3.88851250114e-08  1.94606129585e-13  2.66976244721e-06
4             459_run0       0      0   -2.79115200043    0.0681385472417                4  3.82922388992e-06  1.91639673239e-11  2.66976244721e-06
5             459_run0       0      0    -1.3000651598    0.0679288357496                2   0.00017696986087  8.85827527822e-10  2.66976244721e-06
6             459_run0       0      0   -3.12633061409    0.0681385472417                5  1.67718461507e-06  8.39372230876e-12  2.66976244721e-06
7             459_run0       0      0   -3.98068499565    0.0681385472417                6  2.17162158049e-07  1.08681904949e-12  2.66976244721e-06
8             460_run0       0      0    4.76600265503  3.51661810782e-07                1     0.999936551642     0.999961096909  3.86832196238e-05
9             460_run0       0      0  -0.359799444675    0.0497359000146                2   0.00226731352787  1.44187769763e-07  3.86832196238e-05
...
                   0  1  2                3                4   5                  6                  7               8
9156  DECOY_592_run0  0  1    -3.0585565567  0.0681385472417  10  1.97975133585e-06  1.35160933632e-06  0.832455912569
9157  DECOY_592_run0  0  1  -0.542050778866  0.0541973598301   2   0.00137243237197  0.000938268380851  0.832455912569
9158  DECOY_592_run0  0  1   -4.28670549393  0.0681385472417  16  1.06635006309e-07  7.28013652377e-08  0.832455912569
9159  DECOY_592_run0  0  1   -3.64450979233  0.0681385472417  13  4.80449179963e-07  3.28010195992e-07  0.832455912569
9160  DECOY_592_run0  0  1   -2.68344449997  0.0681385472417   7  5.00664173409e-06  3.41812836387e-06  0.832455912569
9161  DECOY_592_run0  0  1   -2.83036255836  0.0681385472417   9  3.47432890776e-06  2.37198597753e-06  0.832455912569
9162  DECOY_592_run0  0  1   -2.75949048996  0.0681385472417   8  4.14263355873e-06  2.82825130814e-06  0.832455912569
9163  DECOY_592_run0  0  1   -4.25948238373  0.0681385472417  15  1.13548817053e-07  7.75215311201e-08  0.832455912569
9164  DECOY_592_run0  0  1   -4.12553596497  0.0681385472417  14  1.54874069216e-07  1.05734923442e-07  0.832455912569
9165  DECOY_592_run0  0  1   -3.57327675819  0.0681385472417  12  5.69465197972e-07  3.88782863225e-07  0.832455912569
                     0       1      2                3                  4                5                  6                  7                  8
0  transition_group_id  run_id  decoy          d_score            m_score  peak_group_rank           pg_score            h_score           h0_score
1             459_run0       0      0    5.50868988037  1.09357003453e-08                1      0.99999499537     0.999997328445  2.66976244721e-06
2             459_run0       0      0   -1.30364465714    0.0679288357496                3  0.000175293855794  8.77436767265e-10  2.66976244721e-06
3             459_run0       0      0   -4.72917842865    0.0681385472417                7  3.88851250114e-08  1.94606129585e-13  2.66976244721e-06
4             459_run0       0      0   -2.79115200043    0.0681385472417                4  3.82922388992e-06  1.91639673239e-11  2.66976244721e-06
5             459_run0       0      0    -1.3000651598    0.0679288357496                2   0.00017696986087  8.85827527822e-10  2.66976244721e-06
6             459_run0       0      0   -3.12633061409    0.0681385472417                5  1.67718461507e-06  8.39372230876e-12  2.66976244721e-06
7             459_run0       0      0   -3.98068499565    0.0681385472417                6  2.17162158049e-07  1.08681904949e-12  2.66976244721e-06
8             460_run0       0      0    4.76600265503  3.51661810782e-07                1     0.999936551642     0.999961096909  3.86832196238e-05
9             460_run0       0      0  -0.359799444675    0.0497359000146                2   0.00226731352787  1.44187769763e-07  3.86832196238e-05
...
                   0  1  2                3                4   5                  6                  7               8
9156  DECOY_592_run0  0  1    -3.0585565567  0.0681385472417  10  1.97975133585e-06  1.35160933632e-06  0.832455912569
9157  DECOY_592_run0  0  1  -0.542050778866  0.0541973598301   2   0.00137243237197  0.000938268380851  0.832455912569
9158  DECOY_592_run0  0  1   -4.28670549393  0.0681385472417  16  1.06635006309e-07  7.28013652377e-08  0.832455912569
9159  DECOY_592_run0  0  1   -3.64450979233  0.0681385472417  13  4.80449179963e-07  3.28010195992e-07  0.832455912569
9160  DECOY_592_run0  0  1   -2.68344449997  0.0681385472417   7  5.00664173409e-06  3.41812836387e-06  0.832455912569
9161  DECOY_592_run0  0  1   -2.83036255836  0.0681385472417   9  3.47432890776e-06  2.37198597753e-06  0.832455912569
9162  DECOY_592_run0  0  1   -2.75949048996  0.0681385472417   8  4.14263355873e-06  2.82825130814e-06  0.832455912569
9163  DECOY_592_run0  0  1   -4.25948238373  0.0681385472417  15  1.13548817053e-07  7.75215311201e-08  0.832455912569
9164  DECOY_592_run0  0  1   -4.12553596497  0.0681385472417  14  1.54874069216e-07  1.05734923442e-07  0.832455912569
9165  DECOY_592_run0  0  1   -3.57327675819  0.0681385472417  12  5.69465197972e-07  3.88782863225e-07  0.832455912569
hex digtest pickled classifier: dbf168136800ec7dcd14ab0be7f9a0fefa94876f
pyprophet test_data.txt --random_seed=42 --compute.probabilities --target.compress_results --out_of_core --out_of_core.sampling_rate=1.000000

used parameters:

    apply_scorer                               : None
    apply_weights                              : None
    compute.probabilities                      : True
    d_score.cutoff                             : -1000.0
    delim.in                                   : '\t'
    delim.out                                  : '\t'
    export.mayu                                : False
    final_statistics.emp_p                     : False
    final_statistics.lambda                    : 0.4
    final_statistics.pfdr                      : False
    ignore.invalid_score_columns               : 0
    is_test                                    : 0
    multiple_files.merge_results               : 0
    num_processes                              : 1
    out_of_core                                : 1
    out_of_core.sampling_rate                  : 1.0
    random_seed                                : 42
    semi_supervised_learner.initial_fdr        : 0.15
    semi_supervised_learner.initial_lambda     : 0.4
    semi_supervised_learner.iteration_fdr      : 0.02
    semi_supervised_learner.iteration_lambda   : 0.4
    semi_supervised_learner.num_iter           : 5
    semi_supervised_learner.stat_best          : 0
    semi_supervised_learner.use_best           : 0
    target.compress_results                    : 1
    target.dir                                 : None
    target.overwrite                           : 0
    target.prefix                              : None
    xeval.fraction                             : 0.5
    xeval.num_iter                             : 5

ERROR: test_data_cutoffs.txt already exists
ERROR: test_data_qvalues.txt already exists
ERROR: test_data_dscores_top_decoy_peaks.txt already exists
ERROR: test_data_report.pdf already exists
ERROR: test_data_svalues.txt already exists
ERROR: test_data_with_dscore_filtered.csv already exists
ERROR: test_data_dscores_top_target_peaks.txt already exists
ERROR: test_data_with_dscore.csv already exists
ERROR: test_data_full_stat.csv already exists
ERROR: test_data_summary_stat.csv already exists
ERROR: test_data_weights.txt already exists
ERROR: test_data_scorer.bin already exists

please use --target.overwrite option


