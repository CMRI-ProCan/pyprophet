                 0                 1                  2                 3      4     5              6               7                  8         9                 10  \
0            qvalue            svalue             pvalue               pep     TP    FP             TN              FN                FDR       FNR              sens
1               0.0  0.00561797758564  4.00124378075e-13  1.1189372154e-08    3.0   0.0  30.0777202073   353.922279793  6.00186567112e-12  0.921875  0.00840519118544
2  0.00999999977648               1.0     0.115923710167     0.50387217863  358.0   3.0  27.0777202073  -1.07772020725   0.00966030918062       0.0               1.0
3    0.019999999553               1.0     0.163474112749    0.692517700379  358.0   5.0  25.0777202073  -1.07772020725    0.0135475788265       0.0               1.0
4   0.0500000007451               1.0     0.636176109314    0.978714423882  360.0  19.0  11.0777202073  -3.07772020725    0.0504901669919       0.0               1.0
5     0.10000000149               1.0     0.879240691662    0.978714423882  361.0  26.0  4.07772020725  -4.07772020725    0.0683347657323       0.0               1.0
6     0.20000000298               NaN                NaN               NaN    NaN   NaN            NaN             NaN                NaN       NaN               NaN
7    0.300000011921               NaN                NaN               NaN    NaN   NaN            NaN             NaN                NaN       NaN               NaN
8     0.40000000596               NaN                NaN               NaN    NaN   NaN            NaN             NaN                NaN       NaN               NaN
9               0.5               NaN                NaN               NaN    NaN   NaN            NaN             NaN                NaN       NaN               NaN

                11
0           cutoff
1    7.35057353973
2    1.68718874454
3    1.60130298138
4  -0.639309346676
5   -1.27669394016
6              NaN
7              NaN
8              NaN
9              NaN
                0       1               2               3      4     5              6               7                8    9     10               11
0           qvalue  svalue          pvalue             pep     TP    FP             TN              FN              FDR  FNR  sens           cutoff
1  0.0683347657323     1.0  0.879240691662  0.978714423882  361.0  26.0  4.07772020725  -4.07772020725  0.0683347657323  0.0   1.0    -1.7101380825
2  0.0683347657323     1.0  0.879240691662  0.978714423882  361.0  26.0  4.07772020725  -4.07772020725  0.0683347657323  0.0   1.0   -1.51942265034
3  0.0683347657323     1.0  0.879240691662  0.978714423882  361.0  26.0  4.07772020725  -4.07772020725  0.0683347657323  0.0   1.0   -1.32870721817
4  0.0664629563689     1.0  0.850725829601  0.978714423882  359.0  26.0  4.07772020725  -2.07772020725  0.0664629563689  0.0   1.0     -1.137991786
5  0.0664629563689     1.0  0.850725829601  0.978714423882  358.0  26.0  4.07772020725  -1.07772020725  0.0664629563689  0.0   1.0  -0.947276413441
6  0.0562315881252     1.0  0.712266802788  0.978714423882  359.0  21.0  9.07772020725  -2.07772020725  0.0562315881252  0.0   1.0  -0.756561040878
7  0.0504901669919     1.0  0.636176109314  0.978714423882  359.0  19.0  11.0777202073  -2.07772020725  0.0504901669919  0.0   1.0  -0.565845608711
8   0.049002636224     1.0  0.614166378975  0.978714423882  359.0  18.0  12.0777202073  -2.07772020725   0.049002636224  0.0   1.0  -0.375130236149
9  0.0419502854347     1.0  0.522980213165  0.978714423882  359.0  16.0  14.0777202073  -2.07772020725  0.0419502854347  0.0   1.0  -0.184414818883
...
                   0                 1                  2                 3      4    5              6              7                  8               9                 10  \
42   7.5717093706e-10    0.297752797604  2.67533728504e-09  1.1189372154e-08  106.0  0.0  30.0777202073  250.922279793   7.5717093706e-10  0.892857134342    0.296983421885
43  3.64124286278e-10     0.23033708334  1.01091046645e-09  1.1189372154e-08   82.0  0.0  30.0777202073  274.922279793   3.6984529328e-10  0.901315808296    0.229741892402
44  1.23070859059e-10    0.162921354175  2.37937003433e-10  1.1189372154e-08   58.0  0.0  30.0777202073  298.922279793  1.23070859059e-10  0.908536612988    0.162500362918
45  4.29364876986e-11   0.0898876413703  4.57989202118e-11  1.1189372154e-08   33.0  0.0  30.0777202073  323.922279793  4.29364876986e-11  0.915254235268   0.0924571030398
46  3.90060206357e-11   0.0449438206851  2.11914930048e-11  1.1189372154e-08   16.0  0.0  30.0777202073  340.922279793  3.97340493841e-11  0.918918907642   0.0448276863223
47  3.20730109138e-11   0.0280898883939  1.06910036379e-11  1.1189372154e-08   11.0  0.0  30.0777202073  345.922279793  3.20730109138e-11  0.920212745667   0.0308190343466
48  1.17023057911e-11   0.0112359551713  1.56030743881e-12  1.1189372154e-08    5.0  0.0  30.0777202073  351.922279793  1.17023057911e-11  0.921465992928   0.0140086519757
49  6.00186567112e-12  0.00561797758564  4.00124378075e-13  1.1189372154e-08    1.0  0.0  30.0777202073  355.922279793  6.00186567112e-12        0.921875  0.00280173039515
50  6.00186567112e-12  0.00561797758564  4.00124378075e-13  1.1189372154e-08    1.0  0.0  30.0777202073  355.922279793  6.00186567112e-12        0.921875  0.00280173039515
51  6.00186567112e-12  0.00561797758564  4.00124378075e-13  1.1189372154e-08    1.0  0.0  30.0777202073  355.922279793  6.00186567112e-12        0.921875  0.00280173039515

               11
42  6.10919332504
43  6.29990911484
44   6.4906244278
45  6.68133974075
46  6.87205505371
47  7.06277036667
48  7.25348615646
49  7.44420146942
50  7.63491678238
51  7.82563209534
         0         1         2         3         4         5         6        7         8         9     ...           41        42        43       44        45       46  \
0 -1.710138 -1.519423 -1.328707 -1.137992 -0.947276 -0.756561 -0.565846 -0.37513 -0.184415  0.006301    ...     6.109193  6.299909  6.490624  6.68134  6.872055  7.06277

         47        48        49        50
0  7.253486  7.444201  7.634917  7.825632

[1 rows x 51 columns]
    0    1    2    3    4    5    6    7    8    9     ...           41        42        43        44        45       46        47        48        49        50
0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0    ...     0.297753  0.230337  0.162921  0.089888  0.044944  0.02809  0.011236  0.005618  0.005618  0.005618

[1 rows x 51 columns]
         0         1         2         3         4         5        6         7        8        9       ...                 41            42            43            44  \
0  0.068335  0.068335  0.068335  0.066463  0.066463  0.056232  0.05049  0.049003  0.04195  0.04195      ...       7.571709e-10  3.641243e-10  1.230709e-10  4.293649e-11

             45            46            47            48            49            50
0  3.900602e-11  3.207301e-11  1.170231e-11  6.001866e-12  6.001866e-12  6.001866e-12

[1 rows x 51 columns]
        0         1         2         3         4         5         6         7         8         9      ...          377       378       379       380       381       382  \
0  5.930396  4.844372  4.081255  5.877686  5.298283  5.458693  6.354819  3.522169  6.585752  4.958671    ...     6.390321  2.801703  5.583963  5.803881  5.569912 -0.880525

        383       384       385       386
0  5.473346  5.880577  6.787158  5.992922

[1 rows x 387 columns]
        0         1         2         3         4         5         6         7         8         9      ...         377       378       379       380       381       382  \
0  1.204239  2.468165 -0.030195  0.761202  0.069954 -1.339428 -0.159556  1.228629  1.414282  0.248127    ...    -2.55517  0.163898  0.125287 -0.926253  0.283035 -0.110088

        383       384       385       386
0 -1.303184 -0.426508  0.170572  1.699818

[1 rows x 387 columns]
                    0       1      2                3                  4                  5                  6                7                  8                  9   \
0  transition_group_id  run_id  decoy          d_score            p_value                pep            m_score  peak_group_rank           pg_score            h_score
1             459_run0       0      0    5.93039608002  7.73400721243e-09   1.1189372154e-08  1.64786362333e-09                1     0.999968429542     0.999981366622
2             459_run0       0      0   -1.45747971535     0.879240691662     0.978714423882    0.0683347657323                2  0.000200078733184  6.31792311791e-09
3             459_run0       0      0   -6.28761672974     0.879240691662     0.978714423882    0.0683347657323                7  1.40375189613e-09  4.43176640877e-14
4             459_run0       0      0   -3.57783794403     0.879240691662     0.978714423882    0.0683347657323                5   1.0438359675e-06  3.29548406938e-11
5             459_run0       0      0   -1.67723977566     0.879240691662     0.978714423882    0.0683347657323                3   0.00011566269244  3.65199385678e-09
6             459_run0       0      0    -3.0874774456     0.879240691662     0.978714423882    0.0683347657323                4  3.49724187448e-06  1.10411343538e-10
7             459_run0       0      0   -5.10425901413     0.879240691662     0.978714423882    0.0683347657323                6  2.48241750984e-08  7.83720743468e-13
8             460_run0       0      0    4.84437179565  9.17990109883e-06  1.86058356692e-05  1.04317052774e-06                1     0.999464995548     0.999636179426
9             460_run0       0      0  -0.937884032726     0.850725829601     0.978714423882    0.0664629563689                4  0.000733061928703  3.92546329168e-07

                  10
0           h0_score
1  1.86232641265e-05
2  1.86232641265e-05
3  1.86232641265e-05
4  1.86232641265e-05
5  1.86232641265e-05
6  1.86232641265e-05
7  1.86232641265e-05
8  0.000360738933972
9  0.000360738933972
...
                  0  1  2                3               4               5                6   7                  8                  9               10
9156  DECOY_592_run0  0  1   -3.79255008698  0.879240691662  0.978714423882  0.0683347657323  10  6.15520299056e-07  3.19884314084e-07  0.700715197088
9157  DECOY_592_run0  0  1  -0.799727678299  0.712266802788  0.978714423882  0.0562315881252   3    0.0010359429656  0.000538934865442  0.700715197088
9158  DECOY_592_run0  0  1   -3.67973208427  0.879240691662  0.978714423882  0.0683347657323   9  8.12329740251e-07  4.22165756851e-07  0.700715197088
9159  DECOY_592_run0  0  1   -4.42402982712  0.879240691662  0.978714423882  0.0683347657323  14  1.30756766764e-07  6.79539219588e-08  0.700715197088
9160  DECOY_592_run0  0  1   -2.66538405418  0.879240691662  0.978714423882  0.0683347657323   7  9.93259871347e-06  5.16199406366e-06  0.700715197088
9161  DECOY_592_run0  0  1   -3.93340969086  0.879240691662  0.978714423882  0.0683347657323  11   4.3544109468e-07    2.262975746e-07  0.700715197088
9162  DECOY_592_run0  0  1   -3.40765666962  0.879240691662  0.978714423882  0.0683347657323   8  1.58736559557e-06  8.24950613285e-07  0.700715197088
9163  DECOY_592_run0  0  1   -5.66616296768  0.879240691662  0.978714423882  0.0683347657323  16  6.32778706284e-09  3.28853264012e-09  0.700715197088
9164  DECOY_592_run0  0  1   -5.14049863815  0.879240691662  0.978714423882  0.0683347657323  15   2.2726014084e-08  1.18106439779e-08  0.700715197088
9165  DECOY_592_run0  0  1   -4.07130098343  0.879240691662  0.978714423882  0.0683347657323  12  3.10397068278e-07  1.61312507699e-07  0.700715197088
                    0       1      2                3                  4                  5                  6                7                  8                  9   \
0  transition_group_id  run_id  decoy          d_score            p_value                pep            m_score  peak_group_rank           pg_score            h_score
1             459_run0       0      0    5.93039608002  7.73400721243e-09   1.1189372154e-08  1.64786362333e-09                1     0.999968429542     0.999981366622
2             459_run0       0      0   -1.45747971535     0.879240691662     0.978714423882    0.0683347657323                2  0.000200078733184  6.31792311791e-09
3             459_run0       0      0   -6.28761672974     0.879240691662     0.978714423882    0.0683347657323                7  1.40375189613e-09  4.43176640877e-14
4             459_run0       0      0   -3.57783794403     0.879240691662     0.978714423882    0.0683347657323                5   1.0438359675e-06  3.29548406938e-11
5             459_run0       0      0   -1.67723977566     0.879240691662     0.978714423882    0.0683347657323                3   0.00011566269244  3.65199385678e-09
6             459_run0       0      0    -3.0874774456     0.879240691662     0.978714423882    0.0683347657323                4  3.49724187448e-06  1.10411343538e-10
7             459_run0       0      0   -5.10425901413     0.879240691662     0.978714423882    0.0683347657323                6  2.48241750984e-08  7.83720743468e-13
8             460_run0       0      0    4.84437179565  9.17990109883e-06  1.86058356692e-05  1.04317052774e-06                1     0.999464995548     0.999636179426
9             460_run0       0      0  -0.937884032726     0.850725829601     0.978714423882    0.0664629563689                4  0.000733061928703  3.92546329168e-07

                  10
0           h0_score
1  1.86232641265e-05
2  1.86232641265e-05
3  1.86232641265e-05
4  1.86232641265e-05
5  1.86232641265e-05
6  1.86232641265e-05
7  1.86232641265e-05
8  0.000360738933972
9  0.000360738933972
...
                  0  1  2                3               4               5                6   7                  8                  9               10
9156  DECOY_592_run0  0  1   -3.79255008698  0.879240691662  0.978714423882  0.0683347657323  10  6.15520299056e-07  3.19884314084e-07  0.700715197088
9157  DECOY_592_run0  0  1  -0.799727678299  0.712266802788  0.978714423882  0.0562315881252   3    0.0010359429656  0.000538934865442  0.700715197088
9158  DECOY_592_run0  0  1   -3.67973208427  0.879240691662  0.978714423882  0.0683347657323   9  8.12329740251e-07  4.22165756851e-07  0.700715197088
9159  DECOY_592_run0  0  1   -4.42402982712  0.879240691662  0.978714423882  0.0683347657323  14  1.30756766764e-07  6.79539219588e-08  0.700715197088
9160  DECOY_592_run0  0  1   -2.66538405418  0.879240691662  0.978714423882  0.0683347657323   7  9.93259871347e-06  5.16199406366e-06  0.700715197088
9161  DECOY_592_run0  0  1   -3.93340969086  0.879240691662  0.978714423882  0.0683347657323  11   4.3544109468e-07    2.262975746e-07  0.700715197088
9162  DECOY_592_run0  0  1   -3.40765666962  0.879240691662  0.978714423882  0.0683347657323   8  1.58736559557e-06  8.24950613285e-07  0.700715197088
9163  DECOY_592_run0  0  1   -5.66616296768  0.879240691662  0.978714423882  0.0683347657323  16  6.32778706284e-09  3.28853264012e-09  0.700715197088
9164  DECOY_592_run0  0  1   -5.14049863815  0.879240691662  0.978714423882  0.0683347657323  15   2.2726014084e-08  1.18106439779e-08  0.700715197088
9165  DECOY_592_run0  0  1   -4.07130098343  0.879240691662  0.978714423882  0.0683347657323  12  3.10397068278e-07  1.61312507699e-07  0.700715197088
hex digtest pickled classifier: df27d8a2cb24a993740d707ba798a67824b18b7f
pyprophet test_data.txt --random_seed=42 --compute.probabilities --target.compress_results --semi_supervised_learner.use_best --semi_supervised_learner.stat_best
 config settings:
     apply_scorer: None
     apply_weights: None
     compute.probabilities: True
     d_score.cutoff: -1000.0
     delim.in:
     delim.out:
     export.mayu: False
     final_statistics.emp_p: False
     final_statistics.lambda: 0.4
     final_statistics.lfdr_eps: 1e-08
     final_statistics.lfdr_monotone: True
     final_statistics.lfdr_transf: probit
     final_statistics.lfdr_trunc: True
     final_statistics.pfdr: False
     final_statistics.pi0_method: smoother
     final_statistics.pi0_smooth_df: 3
     final_statistics.pi0_smooth_log_pi0: False
     ignore.invalid_score_columns: 0
     is_test: 0
     multiple_files.merge_results: 0
     num_processes: 1
     out_of_core: 0
     out_of_core.sampling_rate: 0.1
     random_seed: 42
     semi_supervised_learner.initial_fdr: 0.15
     semi_supervised_learner.initial_lambda: 0.4
     semi_supervised_learner.iteration_fdr: 0.02
     semi_supervised_learner.iteration_lambda: 0.4
     semi_supervised_learner.num_iter: 5
     semi_supervised_learner.stat_best: 1
     semi_supervised_learner.use_best: 1
     target.compress_results: 1
     target.dir: None
     target.overwrite: 0
     target.prefix: None
     xeval.fraction: 0.5
     xeval.num_iter: 5
 process test_data.txt
 learn and apply classifier from input data
 data set contains 387 decoy and 387 target transition groups
 summary input file:
    9165 lines
    774 transition groups
    17 scores including main score
 learn and apply scorer
 start 5 cross evals using 1 processes
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 start learn_randomized
 end learn_randomized
 finished cross evals

 data set contains 387 decoy and 387 target transition groups
 mean m_score = 6.205126e-02, std_dev m_score = 1.620012e-02
 mean s_value = 9.802216e-01, std_dev s_value = 1.122316e-01
 Posterior Probability estimation:
 Estimated number of null 15.00 out of a total of 193.
 Prior for a peakgroup: 0.1016872592
 Prior for a chromatogram: 0.922279792746
 Estimated number of true chromatograms: 356.922279793 out of 387
 Number of target data: 3510

 calculated scoring and statistics
 processing input data finished

used parameters:

    apply_scorer                               : None
    apply_weights                              : None
    compute.probabilities                      : True
    d_score.cutoff                             : -1000.0
    delim.in                                   : '\t'
    delim.out                                  : '\t'
    export.mayu                                : False
    final_statistics.emp_p                     : False
    final_statistics.lambda                    : 0.4
    final_statistics.lfdr_eps                  : 1e-08
    final_statistics.lfdr_monotone             : True
    final_statistics.lfdr_transf               : 'probit'
    final_statistics.lfdr_trunc                : True
    final_statistics.pfdr                      : False
    final_statistics.pi0_method                : 'smoother'
    final_statistics.pi0_smooth_df             : 3
    final_statistics.pi0_smooth_log_pi0        : False
    ignore.invalid_score_columns               : 0
    is_test                                    : 0
    multiple_files.merge_results               : 0
    num_processes                              : 1
    out_of_core                                : 0
    out_of_core.sampling_rate                  : 0.1
    random_seed                                : 42
    semi_supervised_learner.initial_fdr        : 0.15
    semi_supervised_learner.initial_lambda     : 0.4
    semi_supervised_learner.iteration_fdr      : 0.02
    semi_supervised_learner.iteration_lambda   : 0.4
    semi_supervised_learner.num_iter           : 5
    semi_supervised_learner.stat_best          : 1
    semi_supervised_learner.use_best           : 1
    target.compress_results                    : 1
    target.dir                                 : None
    target.overwrite                           : 0
    target.prefix                              : None
    xeval.fraction                             : 0.5
    xeval.num_iter                             : 5


==================================================================================================

   qvalue    svalue        pvalue           pep     TP    FP        TN         FN           FDR  \
0    0.00  0.005618  4.001244e-13  1.118937e-08    3.0   0.0  30.07772  353.92228  6.001866e-12
1    0.01  1.000000  1.159237e-01  5.038722e-01  358.0   3.0  27.07772   -1.07772  9.660309e-03
2    0.02  1.000000  1.634741e-01  6.925177e-01  358.0   5.0  25.07772   -1.07772  1.354758e-02
3    0.05  1.000000  6.361761e-01  9.787144e-01  360.0  19.0  11.07772   -3.07772  5.049017e-02
4    0.10  1.000000  8.792407e-01  9.787144e-01  361.0  26.0   4.07772   -4.07772  6.833477e-02
5    0.20       NaN           NaN           NaN    NaN   NaN       NaN        NaN           NaN
6    0.30       NaN           NaN           NaN    NaN   NaN       NaN        NaN           NaN
7    0.40       NaN           NaN           NaN    NaN   NaN       NaN        NaN           NaN
8    0.50       NaN           NaN           NaN    NaN   NaN       NaN        NaN           NaN

        FNR      sens    cutoff
0  0.921875  0.008405  7.350574
1  0.000000  1.000000  1.687189
2  0.000000  1.000000  1.601303
3  0.000000  1.000000 -0.639309
4  0.000000  1.000000 -1.276694
5       NaN       NaN       NaN
6       NaN       NaN       NaN
7       NaN       NaN       NaN
8       NaN       NaN       NaN

==================================================================================================

WRITTEN:  test_data_summary_stat.csv
WRITTEN:  test_data_full_stat.csv
WRITTEN:  test_data_with_dscore.csv
WRITTEN:  test_data_with_dscore_filtered.csv
WRITTEN:  test_data_report.pdf
WRITTEN:  test_data_cutoffs.txt
WRITTEN:  test_data_svalues.txt
WRITTEN:  test_data_qvalues.txt
WRITTEN:  test_data_dscores_top_target_peaks.txt
WRITTEN:  test_data_dscores_top_decoy_peaks.txt
WRITTEN:  test_data_scorer.bin
WRITTEN:  test_data_weights.txt


